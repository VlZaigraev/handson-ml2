{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_learning",
      "provenance": [],
      "collapsed_sections": [
        "7eav9WB0IZaL",
        "Aezg3o0x2jY9",
        "pFeu6vtv2Uy8"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOghwf+xO1VpCvuZlP9j106"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "WXXQyw9vZ4ky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kho5y7JsZ0yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6caa39-060f-43ff-f8dd-7553ce7b4385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Layers Reusage"
      ],
      "metadata": {
        "id": "CTyT6x6Qbdcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "7eav9WB0IZaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, y):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))"
      ],
      "metadata": {
        "id": "4pE4kmd0Z6Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = dict(), dict()\n",
        "X_A, y_A = dict(), dict()\n",
        "X_B, y_B = dict(), dict()\n",
        "\n",
        "(X['train'], y['train']), (X['test'], y['test']) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X['train'] =  X['train']/255.0\n",
        "X['test'] =  X['test']/255.0\n"
      ],
      "metadata": {
        "id": "3z6qQMNEfxPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_A['train'], y_A['train']), (X_B['train'], y_B['train']) = split_dataset(X['train'],y['train'])\n",
        "\n",
        "(X_A['test'], y_A['test']), (X_B['test'], y_B['test']) = split_dataset(X['test'],y['test'])\n",
        "\n",
        "X_B['train'] = X_B['train'][:200]\n",
        "y_B['train'] = y_B['train'][:200]"
      ],
      "metadata": {
        "id": "stxm3JY6i7m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model A (for 8 classes)"
      ],
      "metadata": {
        "id": "Aezg3o0x2jY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_A():\n",
        "    model_A = keras.Sequential()\n",
        "\n",
        "    model_A.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "\n",
        "    for n_hidden in (300,100,50,50,50):\n",
        "        model_A.add(keras.layers.Dense(n_hidden, activation='selu', use_bias=False))\n",
        "        model_A.add(keras.layers.BatchNormalization())\n",
        "        \n",
        "    model_A.add(keras.layers.Dense(8, activation = 'softmax'))\n",
        "    return model_A\n",
        "\n",
        "model_A = create_model_A()\n",
        "model_A.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer = keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_A.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bokl6sILlJzp",
        "outputId": "b8e412c6-16ab-49d9-bdeb-fd4ad9589521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 300)               235200    \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 300)              1200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 100)               30000     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 100)              400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 50)                5000      \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 50)                2500      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 50)                2500      \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 8)                 408       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 277,808\n",
            "Trainable params: 276,708\n",
            "Non-trainable params: 1,100\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_A.fit(X_A['train'],y_A['train'],\n",
        "                      validation_split=0.3,\n",
        "                      epochs = 100,\n",
        "                      callbacks = [keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqaoE8Syor0t",
        "outputId": "9757d45f-5c17-4919-b3df-411f99350030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 9s 7ms/step - loss: 0.4062 - accuracy: 0.8640 - val_loss: 0.5366 - val_accuracy: 0.8301\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.3182 - accuracy: 0.8914 - val_loss: 0.3237 - val_accuracy: 0.8923\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.2934 - accuracy: 0.8983 - val_loss: 0.3132 - val_accuracy: 0.8935\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2723 - accuracy: 0.9068 - val_loss: 0.3134 - val_accuracy: 0.8927\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2578 - accuracy: 0.9104 - val_loss: 0.2671 - val_accuracy: 0.9108\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2450 - accuracy: 0.9143 - val_loss: 0.2868 - val_accuracy: 0.9026\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2337 - accuracy: 0.9179 - val_loss: 0.2612 - val_accuracy: 0.9133\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2237 - accuracy: 0.9222 - val_loss: 0.2678 - val_accuracy: 0.9178\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2127 - accuracy: 0.9266 - val_loss: 0.2695 - val_accuracy: 0.9108\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.2056 - accuracy: 0.9265 - val_loss: 0.2939 - val_accuracy: 0.9074\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.2019 - accuracy: 0.9289 - val_loss: 0.2472 - val_accuracy: 0.9229\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1952 - accuracy: 0.9305 - val_loss: 0.2464 - val_accuracy: 0.9211\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1905 - accuracy: 0.9325 - val_loss: 0.2823 - val_accuracy: 0.9094\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1845 - accuracy: 0.9335 - val_loss: 0.2648 - val_accuracy: 0.9163\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1782 - accuracy: 0.9371 - val_loss: 0.3498 - val_accuracy: 0.9104\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1712 - accuracy: 0.9386 - val_loss: 0.2573 - val_accuracy: 0.9233\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1694 - accuracy: 0.9399 - val_loss: 0.2554 - val_accuracy: 0.9227\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1663 - accuracy: 0.9410 - val_loss: 0.2394 - val_accuracy: 0.9308\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1619 - accuracy: 0.9414 - val_loss: 0.2460 - val_accuracy: 0.9256\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1587 - accuracy: 0.9423 - val_loss: 0.3168 - val_accuracy: 0.9126\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1595 - accuracy: 0.9436 - val_loss: 0.3347 - val_accuracy: 0.9035\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1537 - accuracy: 0.9436 - val_loss: 0.2754 - val_accuracy: 0.9150\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1434 - accuracy: 0.9484 - val_loss: 0.2499 - val_accuracy: 0.9265\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1496 - accuracy: 0.9460 - val_loss: 0.2401 - val_accuracy: 0.9251\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1425 - accuracy: 0.9482 - val_loss: 0.2590 - val_accuracy: 0.9202\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1371 - accuracy: 0.9492 - val_loss: 0.2572 - val_accuracy: 0.9184\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1379 - accuracy: 0.9506 - val_loss: 0.2543 - val_accuracy: 0.9253\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1320 - accuracy: 0.9521 - val_loss: 0.2731 - val_accuracy: 0.9245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save(\"my_model_A.h5\")"
      ],
      "metadata": {
        "id": "163qfjjf2TBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model for binary classsification (model B)"
      ],
      "metadata": {
        "id": "pFeu6vtv2Uy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_B = create_model_A()\n",
        "\n",
        "model_B.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer = keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "_XT3IQTuI8ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_A.fit(X_A['train'],y_A['train'],\n",
        "                      validation_split=0.3,\n",
        "                      epochs = 100,\n",
        "                      callbacks = [keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sj4uExppern",
        "outputId": "c74cbee3-2b73-41b5-d3ab-7e6764f10721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1343 - accuracy: 0.9511 - val_loss: 0.2718 - val_accuracy: 0.9228\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1299 - accuracy: 0.9529 - val_loss: 0.2616 - val_accuracy: 0.9258\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1280 - accuracy: 0.9538 - val_loss: 0.2616 - val_accuracy: 0.9287\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1244 - accuracy: 0.9544 - val_loss: 0.2989 - val_accuracy: 0.9196\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1241 - accuracy: 0.9546 - val_loss: 0.3452 - val_accuracy: 0.9228\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1189 - accuracy: 0.9564 - val_loss: 0.2738 - val_accuracy: 0.9233\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1227 - accuracy: 0.9543 - val_loss: 0.2750 - val_accuracy: 0.9158\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1240 - accuracy: 0.9548 - val_loss: 0.3131 - val_accuracy: 0.9183\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1206 - accuracy: 0.9557 - val_loss: 0.2963 - val_accuracy: 0.9258\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1143 - accuracy: 0.9586 - val_loss: 0.3108 - val_accuracy: 0.9272\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1129 - accuracy: 0.9591 - val_loss: 0.2631 - val_accuracy: 0.9281\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1127 - accuracy: 0.9576 - val_loss: 0.2911 - val_accuracy: 0.9218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reusing A's weigths"
      ],
      "metadata": {
        "id": "27JEo0EOI-JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transfer_A_model = keras.Sequential(\n",
        "    keras.models.load_model('my_model_A.h5').layers[:-1]\n",
        " ) # all layers excluding output\n",
        "\n",
        "for layer in transfer_A_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "transfer_A_model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "transfer_A_model.compile(loss='binary_crossentropy',\n",
        "                optimizer = keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "transfer_A_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTM_e_AQJqtv",
        "outputId": "2cbf841d-4104-450c-fb27-aa172ec9c518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 300)               235200    \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 300)              1200      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 100)               30000     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 100)              400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 50)                5000      \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 50)                2500      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 50)                2500      \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 50)               200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 277,451\n",
            "Trainable params: 51\n",
            "Non-trainable params: 277,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `transfer_A_model` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `transfer_A_model` on top of a clone of `model_A`:\n",
        "\n",
        "```\n",
        ">> model_A = keras.models.load_model(\"my_model_A.h5\")\n",
        ">> model_A_clone = keras.models.clone_model(model_A)\n",
        ">> model_A_clone.set_weights(model_A.get_weights())\n",
        "```\n"
      ],
      "metadata": {
        "id": "TPqBaJqcMtww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_A_model.fit(X_B['train'],y_B['train'],\n",
        "                     validation_split = 0.3,\n",
        "                     epochs=100,\n",
        "                     callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "id": "5XnenhzGM9Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h2PtnqUXTEri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}