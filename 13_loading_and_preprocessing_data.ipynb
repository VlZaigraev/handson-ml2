{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki3ZL1OKpTwZ"
      },
      "source": [
        "**Chapter 13 – Loading and Preprocessing Data with TensorFlow**\n",
        "\n",
        "_This notebook contains all the sample code and solutions to the exercises in chapter 13._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fxn6q_zpTwe"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir7OxdR1pTwf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXbDhrrpTwg"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8zL-SihnpTwg",
        "outputId": "f1c052af-7476-4ea0-fd01-09d790e391e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.5 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 19.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 433 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 135 kB 66.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 206 kB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 23.6 MB 60.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 36.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 23.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 19.2 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 33.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 508 kB 21.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 255 kB 31.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 151 kB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 23.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 173 kB 46.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 179 kB 52.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 267 kB 65.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 435 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 113 kB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 183 kB 46.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 232 kB 67.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 59.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 255 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 265 kB 49.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 107 kB 61.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 267 kB 63.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 267 kB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 266 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 266 kB 52.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 265 kB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 259 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 67.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 232 kB 64.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 232 kB 66.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 230 kB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 155 kB 57.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 154 kB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 179 kB 55.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 172 kB 69.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 41.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 171 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 171 kB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 25.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 66.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 67.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 206 kB 71.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 206 kB 55.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 205 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 205 kB 56.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 205 kB 58.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 203 kB 57.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 203 kB 61.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 203 kB 44.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 202 kB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 202 kB 57.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 201 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 201 kB 57.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 201 kB 48.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 57.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 24.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 64.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 70.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 93 kB 905 kB/s \n",
            "\u001b[K     |████████████████████████████████| 503 kB 43.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 30.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 32.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 380 kB 32.5 MB/s \n",
            "\u001b[?25h  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyfarmhash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.34.2 which is incompatible.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "You can safely ignore the package incompatibility errors.\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    %pip install -q -U tfx\n",
        "    print(\"You can safely ignore the package incompatibility errors.\")\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "RVmnJ9P8rCqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics"
      ],
      "metadata": {
        "id": "cWSeh5CEJoc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_objects, n_features = int(1E3), 10\n",
        "X = tf.random.normal(shape=(n_objects, n_features), stddev = 5)\n",
        "y = tf.random.normal(shape=(n_objects, ), mean = -10, stddev = 10)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "\n",
        "tf.nn.moments(X, axes = [0,1])"
      ],
      "metadata": {
        "id": "0RTmgW4Iq-8_",
        "outputId": "3279517c-167d-4343-cbb8-0ee8b5ee8d66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0544856>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=25.59864>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i, (x_s, y_s) in enumerate(dataset.take(5), start = 1):\n",
        "    print(f\"\"\"\n",
        "    X[{i}] = {x_s}\n",
        "    y[{i}] = {y_s}\n",
        "    {'-'*54}\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "TGZysdEssQuA",
        "outputId": "2e52d1ad-3b59-4626-d729-5f43229a4e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    X[1] = [ 0.5097965  -4.8581986  -0.81164867  6.190033   -3.458878    0.43297905\n",
            " -0.57776046  8.867246    7.598179    9.348671  ]\n",
            "    y[1] = -17.285953521728516\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[2] = [ 4.6078663   2.5444815   0.63235575  5.934783    1.3360726  -8.986338\n",
            " -9.014416    1.2781007   1.1534915   9.917941  ]\n",
            "    y[2] = -19.71023941040039\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[3] = [ -4.7229524   -2.095       -0.18447204  -0.6224143    1.0430775\n",
            "   0.6071024    0.30097777  -5.0319533   -3.558369   -14.671318  ]\n",
            "    y[3] = -14.945405006408691\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[4] = [ 7.1795945  -2.5722125   6.0105424  -0.10796881 -1.1245143  -5.535875\n",
            " -0.83877206  2.671073   -1.2804797  -6.9400854 ]\n",
            "    y[4] = 3.21343994140625\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[5] = [ 2.6259732  -0.5168303   0.82936615 -5.1852484   2.0407796  -0.38768512\n",
            " -3.3539722  -1.4524497  -2.2390363  -3.1496148 ]\n",
            "    y[5] = -23.784568786621094\n",
            "    ------------------------------------------------------\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.batch(7)) # 1000 // 7 = 142"
      ],
      "metadata": {
        "id": "IHwK9ITVte7A",
        "outputId": "0bc1fbe0-ce66-407e-b383-bb194490c6c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*dataset.batch(27).unbatch().take(1))"
      ],
      "metadata": {
        "id": "DJtLJ-lzFsmb",
        "outputId": "d6fb5b0a-2ff7-4744-fba1-a91e3bceb3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([ 0.5097965 , -4.8581986 , -0.81164867,  6.190033  , -3.458878  ,\n",
            "        0.43297905, -0.57776046,  8.867246  ,  7.598179  ,  9.348671  ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.285954>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.repeat(3)) # 3*1000"
      ],
      "metadata": {
        "id": "tiQYVrnJHR60",
        "outputId": "dc61e293-3d4a-434b-a83f-63aba01925f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(buffer_size=10, seed = 54) # buffer_size = 10"
      ],
      "metadata": {
        "id": "rYyb5IWTuXWg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_dataset = dataset.map(lambda x, y: (0.5 * (x[:5] + x[5:])**2, y))\n",
        "print(*mapped_dataset.take(5), sep=f\"\\n{'-'*54}\\n\")"
      ],
      "metadata": {
        "id": "GeSPCEY0uaYx",
        "outputId": "8c490341-0dd4-4444-ba82-44adc90efcd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([  3.1171443,  31.452534 ,  15.786334 , 112.349846 ,  35.588203 ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-5.9586744>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([229.67265 ,  20.949066,  24.612728,  51.211483,  10.367193],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-15.388119>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([ 0.44441286, 14.774824  , 32.446323  , 95.057396  , 17.34483   ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.285954>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([ 4.0931463 , 59.02788   ,  5.096079  ,  0.74867976, 34.953773  ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-14.428833>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([18.648836  , 14.391795  ,  0.18877622, 26.369957  ,  9.733009  ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-12.072515>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*dataset.filter(lambda x, y: tf.norm(x) < 10).take(1))"
      ],
      "metadata": {
        "id": "G5xAvaMg5-Fh",
        "outputId": "a8e617e0-c546-4da1-caaa-e3a9e64316b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([ 2.6259732 , -0.5168303 ,  0.82936615, -5.1852484 ,  2.0407796 ,\n",
            "       -0.38768512, -3.3539722 , -1.4524497 , -2.2390363 , -3.1496148 ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-23.784569>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ds = dataset.batch(54)\n",
        "for batch in batched_ds.take(5):\n",
        "    for i in batch:\n",
        "        print(f\"I = {i.shape}\")"
      ],
      "metadata": {
        "id": "-rwqxccd3OcZ",
        "outputId": "8586824f-df40-4761-bef9-f90b49aa81cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "coPvPwn23dHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the California dataset to multiple CSV files"
      ],
      "metadata": {
        "id": "di47uvdnJqfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZhsdI6agJwgF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()\n",
        "\n",
        "X, y = dict(), dict()\n",
        "\n",
        "X['train'], X['test'], y['train'], y['test'] = train_test_split(\n",
        "    housing['data'], housing['target'].reshape(-1,1),\n",
        "    random_state = 54\n",
        ")\n",
        "\n",
        "X['train'], X['val'], y['train'], y['val'] = train_test_split(\n",
        "    X['train'], y['train'],\n",
        "    random_state = 54\n",
        ")\n"
      ],
      "metadata": {
        "id": "fcagNxgFKAnU",
        "outputId": "09b26cd8-0390-4547-e88a-79d19949b96f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3870, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['val'][0]"
      ],
      "metadata": {
        "id": "qNKMfu63N_kr",
        "outputId": "c746a262-d3f2-4a3b-bde5-7a09ec8d8626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   4.6071    ,   52.        ,    6.03018868,    1.0754717 ,\n",
              "        689.        ,    2.6       ,   37.75      , -122.47      ])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ],
      "metadata": {
        "id": "azUW0x-hMNUS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {split : np.c_[X[split], y[split]] for split in ('train', 'val', 'test')}\n",
        "header = \",\".join(housing.feature_names + [\"MedianHouseValue\"])\n",
        "\n",
        "filepaths = {split: save_to_multiple_csv_files(data[split], split, header, n_parts = 20) for split in data.keys()\n",
        "             }\n",
        "filepaths['val'][:5]"
      ],
      "metadata": {
        "id": "P1OoDtb_N3z1",
        "outputId": "978ac7b6-f21a-4da8-ab81-630ed4490e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_val_00.csv',\n",
              " 'datasets/housing/my_val_01.csv',\n",
              " 'datasets/housing/my_val_02.csv',\n",
              " 'datasets/housing/my_val_03.csv',\n",
              " 'datasets/housing/my_val_04.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_dataset = "
      ],
      "metadata": {
        "id": "F4zRACXZOnlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "13_loading_and_preprocessing_data.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}