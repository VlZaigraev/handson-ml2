{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki3ZL1OKpTwZ"
      },
      "source": [
        "**Chapter 13 – Loading and Preprocessing Data with TensorFlow**\n",
        "\n",
        "_This notebook contains all the sample code and solutions to the exercises in chapter 13._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fxn6q_zpTwe"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir7OxdR1pTwf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXbDhrrpTwg"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8zL-SihnpTwg"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# if IS_COLAB or IS_KAGGLE:\n",
        "#     %pip install -q -U tfx\n",
        "#     print(\"You can safely ignore the package incompatibility errors.\")\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "RVmnJ9P8rCqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics"
      ],
      "metadata": {
        "id": "cWSeh5CEJoc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_objects, n_features = int(1E3), 10\n",
        "X = tf.random.normal(shape=(n_objects, n_features), stddev = 5)\n",
        "y = tf.random.normal(shape=(n_objects, ), mean = -10, stddev = 10)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "\n",
        "tf.nn.moments(X, axes = [0,1])"
      ],
      "metadata": {
        "id": "0RTmgW4Iq-8_",
        "outputId": "d6319f46-07e7-493e-97f8-18d6a9d3f10c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=0.102768265>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=25.171745>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i, (x_s, y_s) in enumerate(dataset.take(5), start = 1):\n",
        "    print(f\"\"\"\n",
        "    X[{i}] = {x_s}\n",
        "    y[{i}] = {y_s}\n",
        "    {'-'*54}\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "TGZysdEssQuA",
        "outputId": "9e9aa5c4-38b2-473b-9786-89edc5f3c3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    X[1] = [ -2.3791492   3.6895828  -5.841405  -11.443262    4.8080134   6.582841\n",
            "  -6.316092    8.652361    1.5965953  -4.547207 ]\n",
            "    y[1] = -22.000883102416992\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[2] = [ 6.1332855  6.7402654  5.127617   1.4579009  3.9343169 -2.7634237\n",
            " -3.2014904 -3.8324695  7.109708  -5.5299864]\n",
            "    y[2] = -5.111372947692871\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[3] = [ -1.7277592    7.442224     1.5269917   -0.4040202    0.01922429\n",
            "  -1.2068157   -1.3811892    1.7028779    2.743732   -12.549468  ]\n",
            "    y[3] = -16.89586639404297\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[4] = [-0.7257024  -5.289981    3.660913    0.6807263   4.6829324   2.269279\n",
            " -2.257893   10.022546    0.7001651  -0.35701635]\n",
            "    y[4] = -21.507286071777344\n",
            "    ------------------------------------------------------\n",
            "    \n",
            "\n",
            "    X[5] = [ 7.624774  -2.2251675  1.6859418  1.7380327  3.3757062  5.754802\n",
            "  5.0753493  3.44203    0.7421321 -7.195111 ]\n",
            "    y[5] = 6.657932281494141\n",
            "    ------------------------------------------------------\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.batch(7)) # 1000 // 7 = 142"
      ],
      "metadata": {
        "id": "IHwK9ITVte7A",
        "outputId": "d419cb13-3d44-406f-a189-5ecb9fa08c48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*dataset.batch(27).unbatch().take(1))"
      ],
      "metadata": {
        "id": "DJtLJ-lzFsmb",
        "outputId": "bc41d258-1634-4f17-905a-eaf67ee6141a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([ -2.3791492,   3.6895828,  -5.841405 , -11.443262 ,   4.8080134,\n",
            "         6.582841 ,  -6.316092 ,   8.652361 ,   1.5965953,  -4.547207 ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-22.000883>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.repeat(3)) # 3*1000"
      ],
      "metadata": {
        "id": "tiQYVrnJHR60",
        "outputId": "45f3df7d-9943-4afa-d851-0b98e890da25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(buffer_size=10, seed = 54) # buffer_size = 10"
      ],
      "metadata": {
        "id": "rYyb5IWTuXWg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_dataset = dataset.map(lambda x, y: (0.5 * (x[:5] + x[5:])**2, y))\n",
        "print(*mapped_dataset.take(5), sep=f\"\\n{'-'*54}\\n\")"
      ],
      "metadata": {
        "id": "GeSPCEY0uaYx",
        "outputId": "85f315e0-f6cc-444c-b8fa-1e0a2ccf5f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([20.351957 ,  6.025712 ,  1.0152572,  4.0992417, 29.434898 ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-10.023413>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([15.544623,  7.786911, 37.28845 , 49.805374,  9.604953],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-13.613569>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([8.8355112e+00, 3.4492753e+00, 3.9507368e+00, 4.8478420e+01,\n",
            "       3.4010030e-02], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-22.000883>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([47.950874, 84.39883 , 13.6026  ,  5.155099, 21.067839],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.719894>)\n",
            "------------------------------------------------------\n",
            "(<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([ 0.753235 ,  6.3077145, 75.39827  , 37.2786   , 10.898772 ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.4576197>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*dataset.filter(lambda x, y: tf.norm(x) < 10).take(1))"
      ],
      "metadata": {
        "id": "G5xAvaMg5-Fh",
        "outputId": "ee2b0b17-2137-48bd-b395-f24003657648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-0.38563824,  3.7454274 , -1.625139  ,  3.3938072 ,  0.10597518,\n",
            "        3.705729  ,  2.893445  , -3.7528381 , -1.2541567 ,  0.77914983],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=-10.03923>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batched_ds = dataset.batch(54)\n",
        "for batch in batched_ds.take(5):\n",
        "    for i in batch:\n",
        "        print(f\"I = {i.shape}\")"
      ],
      "metadata": {
        "id": "-rwqxccd3OcZ",
        "outputId": "5a8fbcb2-4da4-41a8-defc-1e138667b5b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n",
            "I = (54, 10)\n",
            "I = (54,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(batched_ds.repeat(1000000))"
      ],
      "metadata": {
        "id": "coPvPwn23dHZ",
        "outputId": "37cceb20-f249-40a3-fef2-39df724e364f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19000000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the California dataset to multiple CSV files"
      ],
      "metadata": {
        "id": "di47uvdnJqfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data to multiple csv"
      ],
      "metadata": {
        "id": "AvtGwt9PS7Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZhsdI6agJwgF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()\n",
        "\n",
        "X, y = dict(), dict()\n",
        "\n",
        "X['train'], X['test'], y['train'], y['test'] = train_test_split(\n",
        "    housing['data'], housing['target'].reshape(-1,1),\n",
        "    random_state = 54\n",
        ")\n",
        "\n",
        "X['train'], X['val'], y['train'], y['val'] = train_test_split(\n",
        "    X['train'], y['train'],\n",
        "    random_state = 54\n",
        ")\n",
        "\n",
        "split = 'train'\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X[split])\n",
        "\n",
        "X_mean_var = {split: tf.nn.moments(X[split], axes = [0]) for split in X.keys()}\n",
        "\n",
        "for split in X.keys():\n",
        "    X_mean_var[split] = (tf.cast(X_mean_var[split][0], tf.float32),\n",
        "                         tf.cast(X_mean_var[split][1], tf.float32))"
      ],
      "metadata": {
        "id": "fcagNxgFKAnU"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean_var['test']"
      ],
      "metadata": {
        "id": "7V9IcsjvsZXj",
        "outputId": "8e46a379-8021-4eff-e9c2-2c5b78ff572d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 3.8953583e+00,  2.8606588e+01,  5.4673748e+00,  1.1041431e+00,\n",
              "         1.4298213e+03,  2.9509528e+00,  3.5653744e+01, -1.1958934e+02],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([3.6592014e+00, 1.5707469e+02, 7.8098898e+00, 3.6089209e-01,\n",
              "        1.2627025e+06, 1.2997230e+00, 4.5875440e+00, 4.0762849e+00],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ],
      "metadata": {
        "id": "azUW0x-hMNUS"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {split : np.c_[X[split], y[split]] for split in ('train', 'val', 'test')}\n",
        "header = \",\".join(housing.feature_names + [\"MedianHouseValue\"])\n",
        "\n",
        "filepaths = {split: save_to_multiple_csv_files(data[split], split, header, n_parts = 20) for split in data.keys()\n",
        "             }\n",
        "filepaths['val'][:5]"
      ],
      "metadata": {
        "id": "P1OoDtb_N3z1",
        "outputId": "f8c4d84f-c3df-4d2e-e2a8-0d0c676ea839",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_val_00.csv',\n",
              " 'datasets/housing/my_val_01.csv',\n",
              " 'datasets/housing/my_val_02.csv',\n",
              " 'datasets/housing/my_val_03.csv',\n",
              " 'datasets/housing/my_val_04.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an Input Pipeline"
      ],
      "metadata": {
        "id": "o6Y11ebNS35T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_dataset = {\n",
        "    split: tf.data.Dataset.list_files(filepaths[split], shuffle= True) # by default shuffle = True\n",
        "    for split in data.keys()\n",
        "}\n",
        "print(*filepath_dataset['train'].take(5), sep='\\n')"
      ],
      "metadata": {
        "id": "F4zRACXZOnlk",
        "outputId": "dee2aeb0-1086-4b74-9a76-8d2d2c863d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative for list_files\n",
        "aboba_ds = tf.data.Dataset.from_tensor_slices(filepaths['val']).shuffle(10).take(5)\n",
        "print(*aboba_ds, sep='\\n')"
      ],
      "metadata": {
        "id": "ZyJsTdJIFKQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {split: filepath_dataset[split].interleave(\n",
        "    lambda path: tf.data.TextLineDataset(path).skip(1), # skip first row (header)\n",
        "    cycle_length = tf.data.AUTOTUNE,\n",
        "    #block_length = 16,\n",
        "    num_parallel_calls = tf.data.AUTOTUNE,\n",
        "    deterministic = False\n",
        ") for split in data.keys()}\n",
        "\n",
        "print(*dataset['val'].take(5), sep='\\n\\n')"
      ],
      "metadata": {
        "id": "yneyG4d1HkZW",
        "outputId": "8829799c-8fc9-4430-ef87-f90e571eb3c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'10.7958,25.0,7.950089126559715,0.9857397504456328,1608.0,2.8663101604278074,37.27,-122.03,5.00001', shape=(), dtype=string)\n",
            "\n",
            "tf.Tensor(b'5.8652,20.0,7.116022099447513,0.988950276243094,539.0,2.977900552486188,34.18,-118.9,3.026', shape=(), dtype=string)\n",
            "\n",
            "tf.Tensor(b'2.0057,17.0,5.100806451612903,1.060483870967742,1024.0,2.064516129032258,37.97,-120.33,1.189', shape=(), dtype=string)\n",
            "\n",
            "tf.Tensor(b'2.7344,35.0,5.735955056179775,1.0617977528089888,953.0,2.6769662921348316,37.31,-120.46,0.878', shape=(), dtype=string)\n",
            "\n",
            "tf.Tensor(b'5.1985,30.0,6.334128878281623,1.0190930787589498,2114.0,2.522673031026253,34.0,-118.04,2.792', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X['train'].shape[-1] #8\n",
        "assert n_features == 8, 'aboba'\n",
        "\n",
        "@tf.function\n",
        "def preprocess(line, split = 'train'):\n",
        "    fields = tf.io.decode_csv(line,\n",
        "                              record_defaults=[0.]*n_features + [tf.constant([], dtype=tf.float32)])\n",
        "    x, y = tf.stack(fields[:-1]), tf.stack(fields[-1:])\n",
        "    mean, var = X_mean_var[split]\n",
        "    return (x - mean) / var, y"
      ],
      "metadata": {
        "id": "r8Mv_pcZIbct"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(b'10.7958,25.0,7.950089126559715,0.9857397504456328,1608.0,2.8663101604278074,37.27,-122.03,5.00001')"
      ],
      "metadata": {
        "id": "ZFTRHMraRgE9",
        "outputId": "adaee66d-833e-4144-f539-69c9a9bee02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 1.9781709e+00, -2.2624265e-02,  5.9477699e-01, -7.7682143e-01,\n",
              "         1.4654540e-04, -1.5605444e-03,  3.6099887e-01, -6.1708879e-01],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.00001], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete fn"
      ],
      "metadata": {
        "id": "QsZVw7NU0S74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv_reader_dataset(filepaths, repeat_num = 1, n_readers = tf.data.AUTOTUNE,\n",
        "                       n_read_threads = tf.data.AUTOTUNE, shuffle_buffer_size = 10000,\n",
        "                       n_parse_threads = 5, batch_size = 32):\n",
        "    \n",
        "    return tf.data.Dataset.list_files(filepaths, shuffle = True).repeat(repeat_num).interleave(\n",
        "    lambda path: tf.data.TextLineDataset(path).skip(1),\n",
        "    cycle_length = n_readers,\n",
        "    num_parallel_calls = n_read_threads,\n",
        "    deterministic = False).shuffle(shuffle_buffer_size).map(preprocess, num_parallel_calls = n_parse_threads).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "M0xbZS8mn7hz"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = csv_reader_dataset(filepaths['train'], batch_size=3)\n",
        "for X_batch, y_batch in train_set.take(2):\n",
        "    print(\"X =\", X_batch)\n",
        "    print(\"y =\", y_batch)\n",
        "    print()"
      ],
      "metadata": {
        "id": "cKZChFfdvGCL",
        "outputId": "08d39065-e972-4d24-ccfa-7fe26bccf14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = tf.Tensor(\n",
            "[[ 2.7219290e-01 -2.2624265e-02 -2.4003375e-01 -3.3482653e-01\n",
            "   8.2998414e-04 -2.4873824e-04  3.8725787e-01 -6.0709274e-01]\n",
            " [ 3.3990380e-01  5.8546226e-02  2.6861336e-02 -8.1814337e-01\n",
            "  -4.9866445e-04 -2.9836772e-03  4.5728242e-01 -6.2958431e-01]\n",
            " [-3.6715299e-01  6.4790107e-02 -4.7858879e-01 -8.6362475e-01\n",
            "  -4.6745720e-04  5.9427796e-03 -3.6331865e-01  3.3001697e-01]], shape=(3, 8), dtype=float32)\n",
            "y = tf.Tensor(\n",
            "[[2.307]\n",
            " [2.27 ]\n",
            " [0.973]], shape=(3, 1), dtype=float32)\n",
            "\n",
            "X = tf.Tensor(\n",
            "[[ 5.7708580e-02  1.4839037e-02  2.2341978e-02 -1.8193322e-01\n",
            "  -5.0060262e-05  3.3784460e-03 -3.9395431e-01  3.8749194e-01]\n",
            " [-3.8158506e-01  3.9814573e-02 -9.3437485e-02 -6.7295682e-01\n",
            "  -3.8007690e-04 -2.8853829e-03  2.5377330e-01 -6.7318536e-02]\n",
            " [ 4.3704927e-01  1.3971671e-01 -9.4473727e-02 -1.0433053e+00\n",
            "  -5.2285008e-04 -3.2577531e-03 -3.1079984e-01  3.3251455e-01]], shape=(3, 8), dtype=float32)\n",
            "y = tf.Tensor(\n",
            "[[2.259]\n",
            " [0.662]\n",
            " [3.179]], shape=(3, 1), dtype=float32)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model with this dataset"
      ],
      "metadata": {
        "id": "51EyAhCQ0gkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "GC9qZOtvvL2r"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = csv_reader_dataset(filepaths['train'], repeat_num=None)"
      ],
      "metadata": {
        "id": "wq2XyCt22Lqi"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [keras.layers.Dense(30, activation = 'relu', input_shape = X['train'].shape[1:]),\n",
        "     keras.layers.Dense(1)]\n",
        ")\n",
        "\n",
        "model.compile(loss = 'mse', optimizer = keras.optimizers.Adam(learning_rate=1e-3))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gxovLP-r0zGY",
        "outputId": "690d0d7f-3782-49ba-b256-573c034e0378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 30)                270       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_set, steps_per_epoch = len(X['train'] // batch_size) ,epochs=10)"
      ],
      "metadata": {
        "id": "NxpwTdVG1NnA",
        "outputId": "c4c29048-ad2b-4aa4-f5ef-f8cd38dcc82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11610/11610 [==============================] - 35s 3ms/step - loss: 0.4694\n",
            "Epoch 2/10\n",
            "11610/11610 [==============================] - 25s 2ms/step - loss: 0.3408\n",
            "Epoch 3/10\n",
            "11610/11610 [==============================] - 25s 2ms/step - loss: 0.3162\n",
            "Epoch 4/10\n",
            "11610/11610 [==============================] - 25s 2ms/step - loss: 0.3026\n",
            "Epoch 5/10\n",
            "  318/11610 [..............................] - ETA: 25s - loss: 0.2978"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-ec320891fcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mavailable\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mbecause\u001b[0m \u001b[0mit\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mgarbage\u001b[0m \u001b[0mcollected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m       raise ValueError(\n\u001b[1;32m    476\u001b[0m           \u001b[0;34mf\"Signature specifies {len(list(self.signature.input_arg))} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom training loop"
      ],
      "metadata": {
        "id": "vf4Lzwc_3tGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = keras.losses.mean_squared_error\n"
      ],
      "metadata": {
        "id": "DqKCc_Zw1laJ"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, n_epochs, train_filepaths, **kwargs):\n",
        "    train_set = csv_reader_dataset(train_filepaths, repeat_num = n_epochs, **kwargs)\n",
        "\n",
        "    steps_per_epoch = len(X['train']) // kwargs['batch_size']\n",
        "    total_steps = n_epochs * steps_per_epoch\n",
        "\n",
        "    for global_step, (X_batch, y_batch) in enumerate(train_set.take(total_steps), start = 1):\n",
        "        if tf.equal(global_step % 100, 0):\n",
        "            tf.print(f'\\rGlobal step: {global_step} / {total_steps}')\n",
        "            #tf.print(f'Train loss = {loss}')\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses) # accumulate losses\n",
        "            \n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables) # compute grad\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # optimizer's step\n"
      ],
      "metadata": {
        "id": "WRjr3Znp38Q8"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = {\n",
        "    'batch_size': 32\n",
        "}\n",
        "\n",
        "train(model, 10, filepaths['train'], **train_config)"
      ],
      "metadata": {
        "id": "kjyhJi2D7LDG",
        "outputId": "b8ced966-25c4-448b-fc5b-3a6ae346574d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rGlobal step: 100 / 3620\n",
            "Train loss = 0.15878109633922577\n",
            "Global step: 200 / 3620\n",
            "Train loss = 0.20291303098201752\n",
            "Global step: 300 / 3620\n",
            "Train loss = 0.35004815459251404\n",
            "Global step: 400 / 3620\n",
            "Train loss = 0.24711014330387115\n",
            "Global step: 500 / 3620\n",
            "Train loss = 0.3956557512283325\n",
            "Global step: 600 / 3620\n",
            "Train loss = 0.8426235318183899\n",
            "Global step: 700 / 3620\n",
            "Train loss = 0.23693214356899261\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-203-f28f28ff5d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m }\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-202-5b8b1f48bbd9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, train_filepaths, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# optimizer's step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m   \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9348\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9349\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 9350\u001b[0;31m         _ctx, \"Shape\", name, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   9351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9352\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bx1_2yHq7Izn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "13_loading_and_preprocessing_data.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}